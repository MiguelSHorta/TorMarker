{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5891b86",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4129374754674355753\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6290407424\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3238188444203119072\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:29:00.0, compute capability: 7.5\"\n",
      "]\n",
      "2.6.2\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "def curTime():\n",
    "    return round(time.time() * 1000)\n",
    "print(28500 % 150)\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c5854e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((276,), (92,))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 368/368 [00:00<00:00, 686.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368, 1, 150, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extracting datasets to input matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "dataset_size = 28000\n",
    "pred_dataset_size = 7500\n",
    "\n",
    "flow_size = 150\n",
    "number_flows = int(dataset_size/flow_size) -2 #substract 2 so first two flows are ignored\n",
    "pred_number_flows = int(pred_dataset_size/flow_size) - 2\n",
    "seed=2\n",
    "val=0 # For spliting number of flows for training .csv in training and test\n",
    "# paths\n",
    "watermarked_flows = pd.read_csv('caps/TirSkypeTrainBuf50Icbw120.csv', usecols=['Time']) # 28787\n",
    "regular_flows = pd.read_csv('caps/TirSkypeTrainBuf50none.csv', usecols=['Time']) # 45000\n",
    "watermarked_flows_prediction = pd.read_csv('caps/TirSkypeTestBuf50Icbw120.csv', usecols=['Time']) # 10109\n",
    "regular_flows_prediction = pd.read_csv('caps/TirSkypeTestBuf50none.csv', usecols=['Time']) # 8981\n",
    "\n",
    "\n",
    "\n",
    "features = np.zeros((number_flows*2, 1, flow_size, 1))\n",
    "classes = np.zeros(features.shape[0])\n",
    "indexes = np.arange(features.shape[0])\n",
    "\n",
    "# random.Random(seed).shuffle(indexes) # Consistent randomization\n",
    "random.Random(3).shuffle(indexes) # Inconsistent randomization\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "for train_indexes,valid_indexes in skf.split(features, classes):\n",
    "    break\n",
    "    \n",
    "print((train_indexes.shape, valid_indexes.shape))    \n",
    "    \n",
    "\n",
    "def outlier(delay):\n",
    "    return delay if delay < 5000 else 100\n",
    "\n",
    "    \n",
    "watermarked_index = flow_size;\n",
    "regular_index = flow_size;\n",
    "for flow_index in tqdm(range(0, number_flows*2)):      #changed range to start from 0 so first two flows are ignored\n",
    "    if flow_index%2==0:\n",
    "        classes[flow_index]=1\n",
    "        for i in range(flow_size):  \n",
    "            features[flow_index,0,i]=outlier((watermarked_flows['Time'][watermarked_index]-watermarked_flows['Time'][watermarked_index-1])*1000)\n",
    "            watermarked_index+=1\n",
    "    else:\n",
    "        classes[flow_index]=0\n",
    "        for i in range(flow_size):\n",
    "            features[flow_index,0,i]=outlier((regular_flows['Time'][regular_index]-regular_flows['Time'][regular_index-1])*1000)\n",
    "            regular_index+=1\n",
    "    \n",
    "\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4cf5d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#         ================================================================================================\n",
    "#         ======================================== Model of the CNN ======================================\n",
    "#         ================================================================================================\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import (Layer, Dense, Conv2D, MaxPool2D, Dropout, Flatten,\n",
    "                                     GlobalAveragePooling2D, ZeroPadding2D)\n",
    "\n",
    "\n",
    "kernel_size = ([1, 10], [1, 10])\n",
    "filters = (500, 100)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=filters[0], kernel_size=kernel_size[0], strides=(1,1), activation='relu'))\n",
    "model.add(MaxPool2D([1,5]))\n",
    "model.add(Conv2D(filters=filters[1], kernel_size=kernel_size[1], strides=(1,1), activation='relu'))\n",
    "model.add(MaxPool2D([1,5]))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=3000, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(Dense(units=800, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9deb5f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "2/2 [==============================] - 3s 274ms/step - loss: 6.0551 - binary_accuracy: 0.5254 - val_loss: 1.1954 - val_binary_accuracy: 0.5652\n",
      "Epoch 2/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 4.0037 - binary_accuracy: 0.5580 - val_loss: 0.9354 - val_binary_accuracy: 0.5652\n",
      "Epoch 3/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 3.1106 - binary_accuracy: 0.5471 - val_loss: 0.7142 - val_binary_accuracy: 0.6304\n",
      "Epoch 4/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.6351 - binary_accuracy: 0.5906 - val_loss: 0.5323 - val_binary_accuracy: 0.7609\n",
      "Epoch 5/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.3871 - binary_accuracy: 0.5725 - val_loss: 0.4539 - val_binary_accuracy: 0.7717\n",
      "Epoch 6/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.8505 - binary_accuracy: 0.6087 - val_loss: 0.3749 - val_binary_accuracy: 0.9022\n",
      "Epoch 7/150\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.7517 - binary_accuracy: 0.5942 - val_loss: 0.3910 - val_binary_accuracy: 0.9022\n",
      "Epoch 8/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7116 - binary_accuracy: 0.6123 - val_loss: 0.3486 - val_binary_accuracy: 0.9239\n",
      "Epoch 9/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.0985 - binary_accuracy: 0.7464 - val_loss: 0.3498 - val_binary_accuracy: 0.8804\n",
      "Epoch 10/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1137 - binary_accuracy: 0.7029 - val_loss: 0.4018 - val_binary_accuracy: 0.7935\n",
      "Epoch 11/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.7777 - binary_accuracy: 0.7572 - val_loss: 0.4026 - val_binary_accuracy: 0.8043\n",
      "Epoch 12/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.7467 - binary_accuracy: 0.7645 - val_loss: 0.3063 - val_binary_accuracy: 0.9348\n",
      "Epoch 13/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6670 - binary_accuracy: 0.7862 - val_loss: 0.2782 - val_binary_accuracy: 0.9674\n",
      "Epoch 14/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6014 - binary_accuracy: 0.8551 - val_loss: 0.2872 - val_binary_accuracy: 0.9348\n",
      "Epoch 15/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.4445 - binary_accuracy: 0.8514 - val_loss: 0.2673 - val_binary_accuracy: 0.9457\n",
      "Epoch 16/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5193 - binary_accuracy: 0.8514 - val_loss: 0.2153 - val_binary_accuracy: 0.9891\n",
      "Epoch 17/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5485 - binary_accuracy: 0.7935 - val_loss: 0.1955 - val_binary_accuracy: 0.9891\n",
      "Epoch 18/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5269 - binary_accuracy: 0.8623 - val_loss: 0.1795 - val_binary_accuracy: 0.9891\n",
      "Epoch 19/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3404 - binary_accuracy: 0.8877 - val_loss: 0.1741 - val_binary_accuracy: 0.9891\n",
      "Epoch 20/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3142 - binary_accuracy: 0.8659 - val_loss: 0.1901 - val_binary_accuracy: 0.9783\n",
      "Epoch 21/150\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3212 - binary_accuracy: 0.8768 - val_loss: 0.1811 - val_binary_accuracy: 0.9891\n",
      "Epoch 22/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2336 - binary_accuracy: 0.9384 - val_loss: 0.1666 - val_binary_accuracy: 0.9891\n",
      "Epoch 23/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2873 - binary_accuracy: 0.9094 - val_loss: 0.1664 - val_binary_accuracy: 0.9891\n",
      "Epoch 24/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.2822 - binary_accuracy: 0.9239 - val_loss: 0.1668 - val_binary_accuracy: 0.9891\n",
      "Epoch 25/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1752 - binary_accuracy: 0.9420 - val_loss: 0.1787 - val_binary_accuracy: 0.9783\n",
      "Epoch 26/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1955 - binary_accuracy: 0.9420 - val_loss: 0.1817 - val_binary_accuracy: 0.9674\n",
      "Epoch 27/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2289 - binary_accuracy: 0.9239 - val_loss: 0.1884 - val_binary_accuracy: 0.9674\n",
      "Epoch 28/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2718 - binary_accuracy: 0.9022 - val_loss: 0.1749 - val_binary_accuracy: 0.9783\n",
      "Epoch 29/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2324 - binary_accuracy: 0.9239 - val_loss: 0.1532 - val_binary_accuracy: 0.9891\n",
      "Epoch 30/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2001 - binary_accuracy: 0.9565 - val_loss: 0.1537 - val_binary_accuracy: 0.9891\n",
      "Epoch 31/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.2052 - binary_accuracy: 0.9312 - val_loss: 0.1467 - val_binary_accuracy: 0.9891\n",
      "Epoch 32/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2553 - binary_accuracy: 0.9457 - val_loss: 0.1543 - val_binary_accuracy: 0.9891\n",
      "Epoch 33/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1846 - binary_accuracy: 0.9457 - val_loss: 0.1609 - val_binary_accuracy: 0.9674\n",
      "Epoch 34/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.2070 - binary_accuracy: 0.9565 - val_loss: 0.1421 - val_binary_accuracy: 0.9891\n",
      "Epoch 35/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1519 - binary_accuracy: 0.9457 - val_loss: 0.1324 - val_binary_accuracy: 0.9891\n",
      "Epoch 36/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1654 - binary_accuracy: 0.9565 - val_loss: 0.1301 - val_binary_accuracy: 0.9891\n",
      "Epoch 37/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1627 - binary_accuracy: 0.9674 - val_loss: 0.1302 - val_binary_accuracy: 0.9891\n",
      "Epoch 38/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0880 - binary_accuracy: 0.9638 - val_loss: 0.1348 - val_binary_accuracy: 0.9783\n",
      "Epoch 39/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1314 - binary_accuracy: 0.9565 - val_loss: 0.1268 - val_binary_accuracy: 0.9891\n",
      "Epoch 40/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1279 - binary_accuracy: 0.9674 - val_loss: 0.1236 - val_binary_accuracy: 0.9891\n",
      "Epoch 41/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1282 - binary_accuracy: 0.9601 - val_loss: 0.1214 - val_binary_accuracy: 0.9891\n",
      "Epoch 42/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1829 - binary_accuracy: 0.9529 - val_loss: 0.1190 - val_binary_accuracy: 0.9891\n",
      "Epoch 43/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1516 - binary_accuracy: 0.9565 - val_loss: 0.1153 - val_binary_accuracy: 0.9891\n",
      "Epoch 44/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1332 - binary_accuracy: 0.9674 - val_loss: 0.1089 - val_binary_accuracy: 0.9891\n",
      "Epoch 45/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1187 - binary_accuracy: 0.9601 - val_loss: 0.1032 - val_binary_accuracy: 0.9891\n",
      "Epoch 46/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1873 - binary_accuracy: 0.9565 - val_loss: 0.0992 - val_binary_accuracy: 0.9891\n",
      "Epoch 47/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1043 - binary_accuracy: 0.9710 - val_loss: 0.0982 - val_binary_accuracy: 0.9783\n",
      "Epoch 48/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1091 - binary_accuracy: 0.9710 - val_loss: 0.0983 - val_binary_accuracy: 0.9891\n",
      "Epoch 49/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0779 - binary_accuracy: 0.9783 - val_loss: 0.1060 - val_binary_accuracy: 0.9891\n",
      "Epoch 50/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0886 - binary_accuracy: 0.9819 - val_loss: 0.1132 - val_binary_accuracy: 0.9891\n",
      "Epoch 51/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1034 - binary_accuracy: 0.9710 - val_loss: 0.1131 - val_binary_accuracy: 0.9891\n",
      "Epoch 52/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1281 - binary_accuracy: 0.9638 - val_loss: 0.1029 - val_binary_accuracy: 0.9891\n",
      "Epoch 53/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0537 - binary_accuracy: 0.9819 - val_loss: 0.0965 - val_binary_accuracy: 0.9783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0557 - binary_accuracy: 0.9891 - val_loss: 0.1015 - val_binary_accuracy: 0.9783\n",
      "Epoch 55/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0946 - binary_accuracy: 0.9674 - val_loss: 0.0906 - val_binary_accuracy: 0.9783\n",
      "Epoch 56/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0696 - binary_accuracy: 0.9819 - val_loss: 0.0770 - val_binary_accuracy: 0.9891\n",
      "Epoch 57/150\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0385 - binary_accuracy: 0.9891 - val_loss: 0.0868 - val_binary_accuracy: 0.9891\n",
      "Epoch 58/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1266 - binary_accuracy: 0.9601 - val_loss: 0.0949 - val_binary_accuracy: 0.9891\n",
      "Epoch 59/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0799 - binary_accuracy: 0.9746 - val_loss: 0.0836 - val_binary_accuracy: 0.9891\n",
      "Epoch 60/150\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1406 - binary_accuracy: 0.9783 - val_loss: 0.0684 - val_binary_accuracy: 0.9891\n",
      "Epoch 61/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0517 - binary_accuracy: 0.9819 - val_loss: 0.0662 - val_binary_accuracy: 0.9783\n",
      "Epoch 62/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0340 - binary_accuracy: 0.9819 - val_loss: 0.0769 - val_binary_accuracy: 0.9783\n",
      "Epoch 63/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0503 - binary_accuracy: 0.9855 - val_loss: 0.0694 - val_binary_accuracy: 0.9891\n",
      "Epoch 64/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0379 - binary_accuracy: 0.9928 - val_loss: 0.0730 - val_binary_accuracy: 0.9891\n",
      "Epoch 65/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0242 - binary_accuracy: 0.9964 - val_loss: 0.0800 - val_binary_accuracy: 0.9891\n",
      "Epoch 66/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0357 - binary_accuracy: 0.9928 - val_loss: 0.0754 - val_binary_accuracy: 0.9891\n",
      "Epoch 67/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0879 - binary_accuracy: 0.9783 - val_loss: 0.0626 - val_binary_accuracy: 0.9891\n",
      "Epoch 68/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0389 - binary_accuracy: 0.9928 - val_loss: 0.0584 - val_binary_accuracy: 0.9891\n",
      "Epoch 69/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0360 - binary_accuracy: 0.9928 - val_loss: 0.0571 - val_binary_accuracy: 0.9891\n",
      "Epoch 70/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0244 - binary_accuracy: 1.0000 - val_loss: 0.0577 - val_binary_accuracy: 0.9891\n",
      "Epoch 71/150\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0845 - binary_accuracy: 0.9891 - val_loss: 0.0566 - val_binary_accuracy: 0.9891\n",
      "Epoch 72/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0339 - binary_accuracy: 0.9891 - val_loss: 0.0623 - val_binary_accuracy: 0.9891\n",
      "Epoch 73/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0197 - binary_accuracy: 0.9964 - val_loss: 0.0746 - val_binary_accuracy: 0.9891\n",
      "Epoch 74/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0204 - binary_accuracy: 0.9928 - val_loss: 0.0906 - val_binary_accuracy: 0.9891\n",
      "Epoch 75/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0161 - binary_accuracy: 0.9964 - val_loss: 0.1090 - val_binary_accuracy: 0.9891\n",
      "Epoch 76/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0383 - binary_accuracy: 0.9855 - val_loss: 0.1074 - val_binary_accuracy: 0.9891\n",
      "Epoch 77/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0353 - binary_accuracy: 0.9855 - val_loss: 0.0894 - val_binary_accuracy: 0.9891\n",
      "Epoch 78/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0451 - binary_accuracy: 0.9964 - val_loss: 0.0710 - val_binary_accuracy: 0.9891\n",
      "Epoch 79/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0164 - binary_accuracy: 0.9928 - val_loss: 0.0612 - val_binary_accuracy: 0.9891\n",
      "Epoch 80/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0114 - binary_accuracy: 1.0000 - val_loss: 0.0589 - val_binary_accuracy: 0.9891\n",
      "Epoch 81/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0184 - binary_accuracy: 0.9964 - val_loss: 0.0622 - val_binary_accuracy: 0.9891\n",
      "Epoch 82/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0104 - binary_accuracy: 1.0000 - val_loss: 0.0689 - val_binary_accuracy: 0.9891\n",
      "Epoch 83/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0135 - binary_accuracy: 0.9964 - val_loss: 0.0728 - val_binary_accuracy: 0.9891\n",
      "Epoch 84/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0180 - binary_accuracy: 0.9964 - val_loss: 0.0700 - val_binary_accuracy: 0.9891\n",
      "Epoch 85/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0106 - binary_accuracy: 0.9964 - val_loss: 0.0645 - val_binary_accuracy: 0.9891\n",
      "Epoch 86/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0104 - binary_accuracy: 0.9964 - val_loss: 0.0626 - val_binary_accuracy: 0.9891\n",
      "Epoch 87/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0093 - binary_accuracy: 0.9964 - val_loss: 0.0617 - val_binary_accuracy: 0.9891\n",
      "Epoch 88/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0075 - binary_accuracy: 1.0000 - val_loss: 0.0627 - val_binary_accuracy: 0.9891\n",
      "Epoch 89/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0149 - binary_accuracy: 0.9928 - val_loss: 0.0627 - val_binary_accuracy: 0.9891\n",
      "Epoch 90/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0075 - binary_accuracy: 0.9964 - val_loss: 0.0615 - val_binary_accuracy: 0.9891\n",
      "Epoch 91/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0063 - binary_accuracy: 1.0000 - val_loss: 0.0631 - val_binary_accuracy: 0.9891\n",
      "Epoch 92/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0292 - binary_accuracy: 0.9964 - val_loss: 0.0630 - val_binary_accuracy: 0.9891\n",
      "Epoch 93/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0163 - binary_accuracy: 0.9928 - val_loss: 0.0611 - val_binary_accuracy: 0.9891\n",
      "Epoch 94/150\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0153 - binary_accuracy: 0.9964 - val_loss: 0.0596 - val_binary_accuracy: 0.9891\n",
      "Epoch 95/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0077 - binary_accuracy: 0.9964 - val_loss: 0.0598 - val_binary_accuracy: 0.9891\n",
      "Epoch 96/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0079 - binary_accuracy: 0.9964 - val_loss: 0.0604 - val_binary_accuracy: 0.9891\n",
      "Epoch 97/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0050 - binary_accuracy: 1.0000 - val_loss: 0.0629 - val_binary_accuracy: 0.9891\n",
      "Epoch 98/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0111 - binary_accuracy: 0.9964 - val_loss: 0.0646 - val_binary_accuracy: 0.9891\n",
      "Epoch 99/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0096 - binary_accuracy: 0.9964 - val_loss: 0.0674 - val_binary_accuracy: 0.9891\n",
      "Epoch 100/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0061 - binary_accuracy: 1.0000 - val_loss: 0.0718 - val_binary_accuracy: 0.9891\n",
      "Epoch 101/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0101 - binary_accuracy: 0.9964 - val_loss: 0.0621 - val_binary_accuracy: 0.9891\n",
      "Epoch 102/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0050 - binary_accuracy: 1.0000 - val_loss: 0.0495 - val_binary_accuracy: 0.9891\n",
      "Epoch 103/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0114 - binary_accuracy: 0.9964 - val_loss: 0.0443 - val_binary_accuracy: 0.9891\n",
      "Epoch 104/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0102 - binary_accuracy: 0.9964 - val_loss: 0.0460 - val_binary_accuracy: 0.9891\n",
      "Epoch 105/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0091 - binary_accuracy: 0.9964 - val_loss: 0.0515 - val_binary_accuracy: 0.9891\n",
      "Epoch 106/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0095 - binary_accuracy: 0.9964 - val_loss: 0.0629 - val_binary_accuracy: 0.9891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0051 - binary_accuracy: 1.0000 - val_loss: 0.0780 - val_binary_accuracy: 0.9891\n",
      "Epoch 108/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0082 - binary_accuracy: 0.9964 - val_loss: 0.0835 - val_binary_accuracy: 0.9891\n",
      "Epoch 109/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0136 - binary_accuracy: 0.9964 - val_loss: 0.0784 - val_binary_accuracy: 0.9891\n",
      "Epoch 110/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0044 - binary_accuracy: 1.0000 - val_loss: 0.0751 - val_binary_accuracy: 0.9891\n",
      "Epoch 111/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0072 - binary_accuracy: 1.0000 - val_loss: 0.0722 - val_binary_accuracy: 0.9891\n",
      "Epoch 112/150\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0028 - binary_accuracy: 1.0000 - val_loss: 0.0712 - val_binary_accuracy: 0.9891\n",
      "Epoch 113/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0094 - binary_accuracy: 0.9964 - val_loss: 0.0674 - val_binary_accuracy: 0.9891\n",
      "Epoch 114/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0210 - binary_accuracy: 0.9928 - val_loss: 0.0834 - val_binary_accuracy: 0.9891\n",
      "Epoch 115/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0035 - binary_accuracy: 1.0000 - val_loss: 0.1154 - val_binary_accuracy: 0.9891\n",
      "Epoch 116/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0095 - binary_accuracy: 0.9964 - val_loss: 0.1310 - val_binary_accuracy: 0.9891\n",
      "Epoch 117/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0386 - binary_accuracy: 0.9783 - val_loss: 0.0723 - val_binary_accuracy: 0.9891\n",
      "Epoch 118/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0036 - binary_accuracy: 1.0000 - val_loss: 0.1014 - val_binary_accuracy: 0.9674\n",
      "Epoch 119/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0746 - binary_accuracy: 0.9710 - val_loss: 0.1073 - val_binary_accuracy: 0.9674\n",
      "Epoch 120/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0641 - binary_accuracy: 0.9710 - val_loss: 0.0433 - val_binary_accuracy: 0.9891\n",
      "Epoch 121/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 0.0911 - val_binary_accuracy: 0.9891\n",
      "Epoch 122/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0249 - binary_accuracy: 0.9928 - val_loss: 0.1191 - val_binary_accuracy: 0.9891\n",
      "Epoch 123/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0620 - binary_accuracy: 0.9783 - val_loss: 0.0842 - val_binary_accuracy: 0.9891\n",
      "Epoch 124/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0266 - binary_accuracy: 0.9891 - val_loss: 0.0374 - val_binary_accuracy: 0.9891\n",
      "Epoch 125/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0340 - binary_accuracy: 0.9964 - val_loss: 0.0382 - val_binary_accuracy: 0.9783\n",
      "Epoch 126/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0222 - binary_accuracy: 0.9964 - val_loss: 0.0514 - val_binary_accuracy: 0.9783\n",
      "Epoch 127/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0244 - binary_accuracy: 0.9928 - val_loss: 0.0371 - val_binary_accuracy: 0.9674\n",
      "Epoch 128/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0171 - binary_accuracy: 0.9964 - val_loss: 0.0739 - val_binary_accuracy: 0.9891\n",
      "Epoch 129/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0022 - binary_accuracy: 1.0000 - val_loss: 0.1222 - val_binary_accuracy: 0.9891\n",
      "Epoch 130/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0240 - binary_accuracy: 0.9928 - val_loss: 0.1139 - val_binary_accuracy: 0.9891\n",
      "Epoch 131/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0060 - binary_accuracy: 0.9964 - val_loss: 0.0732 - val_binary_accuracy: 0.9891\n",
      "Epoch 132/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 0.0566 - val_binary_accuracy: 0.9783\n",
      "Epoch 133/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0060 - binary_accuracy: 1.0000 - val_loss: 0.0705 - val_binary_accuracy: 0.9674\n",
      "Epoch 134/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0318 - binary_accuracy: 0.9891 - val_loss: 0.0731 - val_binary_accuracy: 0.9674\n",
      "Epoch 135/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0239 - binary_accuracy: 0.9891 - val_loss: 0.0559 - val_binary_accuracy: 0.9783\n",
      "Epoch 136/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 0.0824 - val_binary_accuracy: 0.9891\n",
      "Epoch 137/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 0.1214 - val_binary_accuracy: 0.9891\n",
      "Epoch 138/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0152 - binary_accuracy: 0.9928 - val_loss: 0.0703 - val_binary_accuracy: 0.9891\n",
      "Epoch 139/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0033 - binary_accuracy: 1.0000 - val_loss: 0.1497 - val_binary_accuracy: 0.9565\n",
      "Epoch 140/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0710 - binary_accuracy: 0.9638 - val_loss: 0.1187 - val_binary_accuracy: 0.9674\n",
      "Epoch 141/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0659 - binary_accuracy: 0.9746 - val_loss: 0.0411 - val_binary_accuracy: 0.9891\n",
      "Epoch 142/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0161 - binary_accuracy: 0.9964 - val_loss: 0.1214 - val_binary_accuracy: 0.9891\n",
      "Epoch 143/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0616 - binary_accuracy: 0.9783 - val_loss: 0.1495 - val_binary_accuracy: 0.9891\n",
      "Epoch 144/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2093 - binary_accuracy: 0.9457 - val_loss: 0.0442 - val_binary_accuracy: 0.9891\n",
      "Epoch 145/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0165 - binary_accuracy: 0.9891 - val_loss: 0.0434 - val_binary_accuracy: 0.9674\n",
      "Epoch 146/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0215 - binary_accuracy: 0.9964 - val_loss: 0.0717 - val_binary_accuracy: 0.9674\n",
      "Epoch 147/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0325 - binary_accuracy: 0.9891 - val_loss: 0.0382 - val_binary_accuracy: 0.9891\n",
      "Epoch 148/150\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0063 - binary_accuracy: 1.0000 - val_loss: 0.1000 - val_binary_accuracy: 0.9891\n",
      "Epoch 149/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0031 - binary_accuracy: 1.0000 - val_loss: 0.1546 - val_binary_accuracy: 0.9891\n",
      "Epoch 150/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0291 - binary_accuracy: 0.9891 - val_loss: 0.1729 - val_binary_accuracy: 0.9891\n"
     ]
    }
   ],
   "source": [
    "#         ================================================================================================\n",
    "#         ======================================== Training ==============================================\n",
    "#         ================================================================================================\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "learning_rate = 0.0001\n",
    "batch_size=256\n",
    "epochs=150\n",
    "loss = 'binary_crossentropy'\n",
    "callback = EarlyStopping(monitor='val_loss', patience = 50)\n",
    "\n",
    "optimizer=Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer = optimizer, loss=loss, metrics=['binary_accuracy'])\n",
    "timestamp1 = curTime()\n",
    "history = model.fit(features[train_indexes[val:]], classes[train_indexes[val:]], validation_data=(features[valid_indexes],classes[valid_indexes]), batch_size=batch_size, epochs=epochs, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a364a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:00<00:00, 676.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TEST', 276, (92,), (96,))\n",
      "FPS|TPR|BINARY-ACC\n",
      "[0.0417 0.7292 0.8438]\n"
     ]
    }
   ],
   "source": [
    "#         ================================================================================================\n",
    "#         ======================================== Testing ==============================================\n",
    "#         ================================================================================================\n",
    "\n",
    "timestamp2 = curTime()\n",
    "\n",
    "features_prediction = np.zeros((pred_number_flows*2, 1, flow_size, 1))\n",
    "classes_prediction = np.zeros(features_prediction.shape[0])\n",
    "\n",
    "pred_watermarked_index = flow_size;\n",
    "pred_regular_index = flow_size;\n",
    "for flow_index in tqdm(range(0, pred_number_flows*2)):      #changed range to start from 0 so first two flows are ignored\n",
    "    if flow_index%2==0:\n",
    "        classes_prediction[flow_index]=1\n",
    "        for i in range(flow_size):  \n",
    "            features_prediction[flow_index,0,i]=outlier((watermarked_flows_prediction['Time'][pred_watermarked_index]-watermarked_flows_prediction['Time'][pred_watermarked_index-1])*1000)\n",
    "            pred_watermarked_index+=1\n",
    "    else:\n",
    "        classes_prediction[flow_index]=0\n",
    "        for i in range(flow_size):\n",
    "            features_prediction[flow_index,0,i]=outlier((regular_flows_prediction['Time'][pred_regular_index]-regular_flows_prediction['Time'][pred_regular_index-1])*1000)\n",
    "            pred_regular_index+=1\n",
    "\n",
    "\n",
    "fp=0; fn=0; tp=0; tn=0\n",
    "pred_classes = classes_prediction\n",
    "timestamp3 = curTime()\n",
    "pred = model.predict(features_prediction)\n",
    "timestamp4 = curTime()\n",
    "print(('TEST',classes[train_indexes].shape[0]-val, classes[valid_indexes].shape, pred_classes.shape))\n",
    "\n",
    "#print(pred_classes)\n",
    "#print(np.around(pred.flatten(),3))\n",
    "for i in range(pred.shape[0]):\n",
    "    if pred_classes[i]==0:\n",
    "        if pred[i]>0.5: fp+=1\n",
    "        else: tn+=1\n",
    "    else:\n",
    "        if pred[i]>0.5: tp+=1\n",
    "        else: fn+=1            \n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "tpr = tp/(tp+fn)\n",
    "# Fall out or false positive rate\n",
    "fpr = fp/(fp+tn)\n",
    "metrics = [fpr, tpr, (tp+tn)/(tn+tp+fp+fn)]\n",
    "print(\"FPS|TPR|BINARY-ACC\")\n",
    "print(np.around(metrics, 4))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d6c12b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST FPS|TPR|BINARY-ACC\n",
      "0,0417 0,7292 0,8438\n",
      "\n",
      "Val - FPS|TPR|BINARY-ACC\n",
      "0,0244 1,0 0,9891\n",
      "(8595, 116)\n"
     ]
    }
   ],
   "source": [
    "#print(('TEST',kernel_size,classes[train_indexes].shape[0]-val, classes[valid_indexes].shape, pred_classes.shape))\n",
    "print('TEST FPS|TPR|BINARY-ACC')\n",
    "results = np.around(metrics,4)\n",
    "listToStr = ' '.join([str(elem) for elem in results])\n",
    "print(listToStr.replace(\".\",\",\"))\n",
    "fp=0; fn=0; tp=0; tn=0    \n",
    "if(True):\n",
    "    pred_classes = classes[valid_indexes]\n",
    "    pred = model.predict(features[valid_indexes])\n",
    "else:\n",
    "    pred_classes = classes[train_indexes]\n",
    "    pred = model.predict(features[train_indexes])\n",
    "#print(pred_classes)\n",
    "#print(np.around(pred.flatten(),3))\n",
    "for i in range(pred.shape[0]):\n",
    "    if pred_classes[i]==0:\n",
    "        if pred[i]>0.5: fp+=1\n",
    "        else: tn+=1\n",
    "    else:\n",
    "        if pred[i]>0.5: tp+=1\n",
    "        else: fn+=1            \n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "tpr = tp/(tp+fn)\n",
    "# Fall out or false positive rate\n",
    "fpr = fp/(fp+tn)\n",
    "metrics = [fpr, tpr, (tp+tn)/(tn+tp+fp+fn)]\n",
    "print(\"\\nVal - FPS|TPR|BINARY-ACC\")\n",
    "results = np.around(metrics,4)\n",
    "listToStr = ' '.join([str(elem) for elem in results])\n",
    "print(listToStr.replace(\".\",\",\"))\n",
    "\n",
    "print((timestamp2-timestamp1,timestamp4-timestamp3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8cf7b20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#         ================================================================================================\n",
    "#         =================================  Testing with same circuits ==================================\n",
    "#         ================================================================================================\n",
    "\n",
    "if val!=0:\n",
    "    fp=0; fn=0; tp=0; tn=0\n",
    "    pred_classes = classes[train_indexes[:val]]\n",
    "    pred = model.predict(features[train_indexes[:val]])\n",
    "    print((kernel_size, classes[train_indexes[:-val]].shape, classes[valid_indexes].shape, pred_classes.shape))\n",
    "    #print(pred_classes)\n",
    "    #print(np.around(pred.flatten(),3))\n",
    "    for i in range(pred.shape[0]):\n",
    "        if pred_classes[i]==0:\n",
    "            if pred[i]>0.5: fp+=1\n",
    "            else: tn+=1\n",
    "        else:\n",
    "            if pred[i]>0.5: tp+=1\n",
    "            else: fn+=1            \n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    tpr = tp/(tp+fn)\n",
    "    # Fall out or false positive rate\n",
    "    fpr = fp/(fp+tn)\n",
    "    metrics = [fpr, tpr, (tp+tn)/(tn+tp+fp+fn)]\n",
    "    print(\"FPS|TPR|BINARY-ACC\")\n",
    "    results = np.around(metrics, 4) \n",
    "    listToStr = ' '.join([str(elem) for elem in results])\n",
    "    print(listToStr.replace(\".\",\",\"))\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
